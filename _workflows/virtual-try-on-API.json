{
  "1": {
    "inputs": {
      "seed": 247561440681096,
      "steps": 8,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "6",
        0
      ],
      "positive": [
        "11",
        0
      ],
      "negative": [
        "11",
        1
      ],
      "latent_image": [
        "11",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "2": {
    "inputs": {
      "samples": [
        "1",
        0
      ],
      "vae": [
        "20",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "3": {
    "inputs": {
      "images": [
        "2",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "6": {
    "inputs": {
      "lora_name": "Catviton.safetensors",
      "strength_model": 1,
      "model": [
        "7",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "7": {
    "inputs": {
      "lora_name": "Catviton.safetensors",
      "strength_model": 1,
      "model": [
        "9",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "9": {
    "inputs": {
      "unet_name": "flux1-fill-dev-fp16-Q8_0-GGUF.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "11": {
    "inputs": {
      "noise_mask": true,
      "positive": [
        "13",
        0
      ],
      "negative": [
        "12",
        0
      ],
      "pixels": [
        "26",
        0
      ],
      "mask": [
        "26",
        1
      ],
      "vae": [
        "20",
        0
      ]
    },
    "class_type": "InpaintModelConditioning",
    "_meta": {
      "title": "InpaintModelConditioning"
    }
  },
  "12": {
    "inputs": {
      "conditioning": [
        "13",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "13": {
    "inputs": {
      "guidance": 30,
      "conditioning": [
        "15",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "15": {
    "inputs": {
      "image_strength": "highest",
      "conditioning": [
        "16",
        0
      ],
      "style_model": [
        "17",
        0
      ],
      "clip_vision_output": [
        "18",
        0
      ]
    },
    "class_type": "StyleModelApplySimple",
    "_meta": {
      "title": "StyleModelApplySimple"
    }
  },
  "16": {
    "inputs": {
      "text": "",
      "clip": [
        "19",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "17": {
    "inputs": {
      "style_model_name": "flux1-redux-dev.safetensors"
    },
    "class_type": "StyleModelLoader",
    "_meta": {
      "title": "Load Style Model"
    }
  },
  "18": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "24",
        0
      ],
      "image": [
        "25",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "19": {
    "inputs": {
      "clip_name1": "t5-v1_1-xxl-encoder-Q6_K.gguf",
      "clip_name2": "clip_l.safetensors",
      "type": "flux"
    },
    "class_type": "DualCLIPLoaderGGUF",
    "_meta": {
      "title": "DualCLIPLoader (GGUF)"
    }
  },
  "20": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "23": {
    "inputs": {
      "VAE": [
        "20",
        0
      ]
    },
    "class_type": "Anything Everywhere",
    "_meta": {
      "title": "Anything Everywhere"
    }
  },
  "24": {
    "inputs": {
      "clip_name": "sigclip_vision_patch14_384.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "25": {
    "inputs": {
      "image": "black_jacket.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "26": {
    "inputs": {
      "patch_mode": "patch_right",
      "output_length": 1536,
      "patch_color": "#FF0000",
      "first_image": [
        "25",
        0
      ],
      "second_image": [
        "29",
        0
      ],
      "second_mask": [
        "28",
        0
      ]
    },
    "class_type": "AddMaskForICLora",
    "_meta": {
      "title": "Add Mask For IC Lora"
    }
  },
  "28": {
    "inputs": {
      "grow": 16,
      "blur": 7,
      "mask": [
        "29",
        1
      ]
    },
    "class_type": "INPAINT_ExpandMask",
    "_meta": {
      "title": "Expand Mask"
    }
  },
  "29": {
    "inputs": {
      "image": "clipspace/clipspace-mask-2102439.png [input]",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "30": {
    "inputs": {
      "width": [
        "26",
        4
      ],
      "height": [
        "26",
        5
      ],
      "position": "top-left",
      "x_offset": [
        "26",
        2
      ],
      "y_offset": [
        "26",
        3
      ],
      "image": [
        "2",
        0
      ]
    },
    "class_type": "ImageCrop+",
    "_meta": {
      "title": "ðŸ”§ Image Crop"
    }
  },
  "31": {
    "inputs": {
      "images": [
        "30",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  }
}